{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytrec_eval\n",
    "import numpy as np\n",
    "from typing import Dict\n",
    "import pandas as pd\n",
    "from pyserini.search import LuceneSearcher\n",
    "import seaborn as sns\n",
    "queries_file = \"data/proc_data/train_sample/sample_queries.tsv\"\n",
    "qrels_file = \"data/proc_data/train_sample/sample_qrels.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = pd.read_csv('data/proc_data/train_sample/sample_queries.tsv', sep=' ', names=['qid', 'query'])\n",
    "qrels = pd.read_csv('data/proc_data/train_sample/sample_qrels.tsv', sep=' ', names=['qid', 'Q0', 'docid', 'rel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(topics.shape)\n",
    "topics.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qrels.drop('Q0', axis=1, inplace=True)\n",
    "qrels.drop('rel', axis=1, inplace=True)\n",
    "print(qrels.shape)\n",
    "qrels.sample(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dummy_qrels() -> Dict[str, Dict[str, int]]:\n",
    "    return {\n",
    "        \"1\": {\"doc1\": 1, \"doc2\": 0, \"doc3\": 1},\n",
    "        \"2\": {\"doc1\": 0, \"doc2\": 1, \"doc3\": 0},\n",
    "    }\n",
    "\n",
    "\n",
    "def create_dummy_run() -> Dict[str, Dict[str, float]]:\n",
    "    return {\n",
    "        \"1\": {\"doc1\": 1.2, \"doc2\": 0.8, \"doc3\": 1.5},\n",
    "        \"2\": {\"doc1\": 0.1, \"doc2\": 1.0, \"doc3\": 0.5},\n",
    "    }\n",
    "\n",
    "\n",
    "def runtest(qrels_file, run_file):\n",
    "    qrels = pytrec_eval.parse_qrel(qrels_file)\n",
    "    run = pytrec_eval.parse_run(run_file)\n",
    "    evaluator = pytrec_eval.RelevanceEvaluator(qrels, {\"map\"})\n",
    "    results = evaluator.evaluate(run)\n",
    "    print(results)\n",
    "\n",
    "\n",
    "def create_run_file(model, queries, qids, run_name):\n",
    "    batch_search_output = model.search(queries, qids)\n",
    "    run = []\n",
    "    for qid, search_results in batch_search_output.items():\n",
    "        for result in search_results:\n",
    "            row_str = f\"{qid} 0 {result.docno} {result.rank} {result.score} {run_name}\"\n",
    "            run.append(row_str)\n",
    "    with open(f\"outputs/{run_name}.run\", \"w\") as f:\n",
    "        for l in run:\n",
    "            f.write(l + \"\\n\")\n",
    "\n",
    "\n",
    "def create_run_file2(queries, qids, run_name):\n",
    "    searcher = LuceneSearcher(\"pyserini/indexes/full_index/\")\n",
    "    BM25 = searcher.set_bm25(0.9, 0.4)\n",
    "    batch_search_output = BM25.search(queries, qids)\n",
    "\n",
    "\n",
    "def evaluate_run(\n",
    "    run: Dict[str, Dict[str, float]],\n",
    "    qrels: Dict[str, Dict[str, int]],\n",
    "    metric: set = {\"map\", \"ndcg\"},\n",
    ") -> Dict[str, float]:\n",
    "    evaluator = pytrec_eval.RelevanceEvaluator(qrels, metric)\n",
    "    results = evaluator.evaluate(run)\n",
    "\n",
    "    measures = {\n",
    "        measure: np.mean(\n",
    "            [query_measures.get(measure, 0) for query_measures in results.values()]\n",
    "        )\n",
    "        for measure in metric\n",
    "    }\n",
    "    return measures\n",
    "\n",
    "def main():\n",
    "    dummy_qrels = create_dummy_qrels()\n",
    "    dummy_run = create_dummy_run()\n",
    "\n",
    "    print(\"Dummy Qrels:\")\n",
    "    for qid, qrels_docs in dummy_qrels.items():\n",
    "        print(f\"{qid}: {qrels_docs}\")\n",
    "\n",
    "    print(\"\\nDummy Run:\")\n",
    "    for qid, run_docs in dummy_run.items():\n",
    "        print(f\"{qid}: {run_docs}\")\n",
    "\n",
    "    evaluation_results = evaluate_run(dummy_run, dummy_qrels)\n",
    "    print(\"\\nEvaluation Results:\")\n",
    "    for metric, value in evaluation_results.items():\n",
    "        print(f\"{metric}: {value}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_word(text, word):\n",
    "    if word in text:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def query_exists_in_text(text, query):\n",
    "    words_in_text = text.lower().split()\n",
    "    for word in query:\n",
    "        if word.lower() in words_in_text:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Example usage\n",
    "text = \"This is a sample text\"\n",
    "query = [\"sample\", \"word\", \"example\"]\n",
    "exists = query_exists_in_text(text, query)\n",
    "print(exists)  # Output: True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_qrels(file_path):\n",
    "    qrels = {}\n",
    "    with open(file_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            qid, q0, docid, rel = line.strip().split()\n",
    "            if qid not in qrels:\n",
    "                qrels[qid] = {}\n",
    "            qrels[qid][docid] = int(rel)\n",
    "    return qrels\n",
    "\n",
    "def read_run(file_path):\n",
    "    run = {}\n",
    "    with open(file_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            qid, _, docid, score = line.strip().split()\n",
    "            if qid not in run:\n",
    "                run[qid] = {}\n",
    "            run[qid][docid] = float(score)\n",
    "    return run\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "qrelz =read_qrels(qrels_file)\n",
    "\n",
    "pd.read_csv(qrels_file, sep=\" \", header=None, names=[\"qid\", \"q0\", \"docid\", \"rel\"],index_col=False).sort_values(by=[\"qid\"]).head()\n",
    "topics = topics.sort_values(by=[\"qid\"]).head()\n",
    "qrels = qrels.sort_values(by=[\"qid\"]).head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "pd.read_csv(queries_file, sep=\" \", header=None, names=[\"qid\", \"query\"],index_col=False).sort_values(by=[\"qid\"]).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyserini.index import IndexReader as index_reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_exists_in_text(text, query):\n",
    "    words_in_text = text.lower().split()\n",
    "    for word in query:\n",
    "        if word.lower() in words_in_text:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Example usage\n",
    "text = \"This is a sample text\"\n",
    "query = [\"sample\", \"word\", \"example\"]\n",
    "exists = query_exists_in_text(text, query)\n",
    "print(exists)  # Output: True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TEXT>\n",
      "htt\n",
      "1 barrel equal to how much litre\n",
      "True\n",
      "<TEXT>\n",
      "htt\n",
      "1 gallon to litre\n",
      "True\n",
      "<TEXT>\n",
      "htt\n",
      "118 area code location\n",
      "True\n",
      "<TEXT>\n",
      "htt\n",
      "21th amendment definition us history\n",
      "True\n",
      "<TEXT>\n",
      "htt\n",
      "49 out of 70 percentage\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "for qid in qrels['qid']:\n",
    "    id = index_reader.convert_internal_docid_to_collection_docid(qid)\n",
    "    query = index_reader.doc_contents(id)\n",
    "    query = topics.loc[topics['qid'] == qid, 'query'].values[0]\n",
    "    docs = index_reader.doc(id).contents( )\n",
    "    print(docs[:10])\n",
    "    print(query)\n",
    "    print(query_exists_in_text(docs, query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'search'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m searcher \u001b[39m=\u001b[39m LuceneSearcher(\u001b[39m\"\u001b[39m\u001b[39mpyserini/indexes/full_index/\u001b[39m\u001b[39m\"\u001b[39m) \n\u001b[1;32m      2\u001b[0m BM25 \u001b[39m=\u001b[39m searcher\u001b[39m.\u001b[39mset_bm25(\u001b[39m0.9\u001b[39m, \u001b[39m0.4\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m BM25\u001b[39m.\u001b[39;49msearch(query, qid)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'search'"
     ]
    }
   ],
   "source": [
    "searcher = LuceneSearcher(\"pyserini/indexes/full_index/\") \n",
    "BM25 = searcher.set_bm25(0.9, 0.4)\n",
    "searcher.search(query,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
