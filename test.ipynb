{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pytrec_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results = {\n",
    "    'q1': {\n",
    "        'doc1': {'rank': 1, 'score': 0.5},\n",
    "        'doc2': {'rank': 2, 'score': 0.4},\n",
    "        'doc3': {'rank': 3, 'score': 0.3},\n",
    "        'doc4': {'rank': 4, 'score': 0.2},\n",
    "        'doc5': {'rank': 5, 'score': 0.1},\n",
    "    },\n",
    "    'q2': {\n",
    "        'doc6': {'rank': 1, 'score': 0.6},\n",
    "        'doc7': {'rank': 2, 'score': 0.5},\n",
    "        'doc8': {'rank': 3, 'score': 0.4},\n",
    "        'doc9': {'rank': 4, 'score': 0.3},\n",
    "        'doc10': {'rank': 5, 'score': 0.2},\n",
    "    },\n",
    "    # ...\n",
    "}\n",
    "\n",
    "# Create a dictionary of query ids and their corresponding relevance judgements\n",
    "qrels = {\n",
    "    'q1': {\n",
    "        'doc1': 1,\n",
    "        'doc2': 0,\n",
    "        'doc3': 1,\n",
    "        'doc4': 0,\n",
    "        'doc5': 1,\n",
    "    },\n",
    "    'q2': {\n",
    "        'doc6': 0,\n",
    "        'doc7': 1,\n",
    "        'doc8': 1,\n",
    "        'doc9': 0,\n",
    "        'doc10': 0,\n",
    "    },\n",
    "    # ...\n",
    "}\n",
    "\n",
    "# Create a dictionary of query ids and their corresponding information need descriptions\n",
    "queries = {\n",
    "    'q1': 'What is the capital of France?',\n",
    "    'q2': 'Who is the author of The Catcher in the Rye?',\n",
    "    # ...\n",
    "}\n",
    "\n",
    "# Create a dictionary of document ids and their corresponding text contents\n",
    "documents = {\n",
    "    'doc1': 'Paris is the capital of France.',\n",
    "    'doc2': 'France is a country in Europe.',\n",
    "    'doc3': 'The Eiffel Tower is located in Paris.',\n",
    "    'doc4': 'Germany is a country in Europe.',\n",
    "    'doc5': 'The Louvre is a museum located in Paris.',\n",
    "    'doc6': 'The Catcher in the Rye is a novel by J.D. Salinger.',\n",
    "    'doc7': 'J.D. Salinger was an American writer.',\n",
    "    'doc8': 'The Catcher in the Rye is a coming-of-age novel.',\n",
    "    'doc9': 'To Kill a Mockingbird is a novel by Harper Lee.',\n",
    "    'doc10': 'Harper Lee was an American novelist.',\n",
    "    # ...\n",
    "}\n",
    "\n",
    "# Create a dictionary of document ids and their corresponding relevance levels for each query\n",
    "relevance_levels = {\n",
    "    'q1': {\n",
    "        'doc1': 1,\n",
    "        'doc2': 0,\n",
    "        'doc3': 2,\n",
    "        'doc4': 0,\n",
    "        'doc5': 1,\n",
    "    },\n",
    "    'q2': {\n",
    "        'doc6': 2,\n",
    "        'doc7': 2,\n",
    "        'doc8': 1,\n",
    "        'doc9': 0,\n",
    "        'doc10': 0,\n",
    "    },\n",
    "    # ...\n",
    "}\n",
    "\n",
    "documents = [\n",
    "    {'id': 'doc1', 'contents': 'Paris is the capital of France.'},\n",
    "    {'id': 'doc2', 'contents': 'France is a country in Europe.'},\n",
    "    {'id': 'doc3', 'contents': 'The Eiffel Tower is located in Paris.'},\n",
    "    {'id': 'doc4', 'contents': 'Germany is a country in Europe.'},\n",
    "    {'id': 'doc5', 'contents': 'The Louvre is a museum located in Paris.'},\n",
    "    {'id': 'doc6', 'contents': 'The Catcher in the Rye is a novel by J.D. Salinger.'},\n",
    "    {'id': 'doc7', 'contents': 'J.D. Salinger was an American writer.'},\n",
    "    {'id': 'doc8', 'contents': 'The Catcher in the Rye is a coming-of-age novel.'},\n",
    "    {'id': 'doc9', 'contents': 'To Kill a Mockingbird is a novel by Harper Lee.'},\n",
    "    {'id': 'doc10', 'contents': 'Harper Lee was an American novelist.'},\n",
    "    # ...\n",
    "]\n",
    "\n",
    "with open('json/output.json', 'w') as f:\n",
    "    for doc in documents:\n",
    "        f.write(json.dumps(doc) + '\\n')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.\n",
      "2023-05-10 09:50:41,667 INFO  [main] index.IndexCollection (IndexCollection.java:380) - Setting log level to INFO\n",
      "2023-05-10 09:50:41,668 INFO  [main] index.IndexCollection (IndexCollection.java:383) - Starting indexer...\n",
      "2023-05-10 09:50:41,668 INFO  [main] index.IndexCollection (IndexCollection.java:384) - ============ Loading Parameters ============\n",
      "2023-05-10 09:50:41,668 INFO  [main] index.IndexCollection (IndexCollection.java:385) - DocumentCollection path: json/\n",
      "2023-05-10 09:50:41,668 INFO  [main] index.IndexCollection (IndexCollection.java:386) - CollectionClass: JsonCollection\n",
      "2023-05-10 09:50:41,668 INFO  [main] index.IndexCollection (IndexCollection.java:387) - Generator: DefaultLuceneDocumentGenerator\n",
      "2023-05-10 09:50:41,668 INFO  [main] index.IndexCollection (IndexCollection.java:388) - Threads: 1\n",
      "2023-05-10 09:50:41,668 INFO  [main] index.IndexCollection (IndexCollection.java:389) - Language: en\n",
      "2023-05-10 09:50:41,668 INFO  [main] index.IndexCollection (IndexCollection.java:390) - Stemmer: porter\n",
      "2023-05-10 09:50:41,669 INFO  [main] index.IndexCollection (IndexCollection.java:391) - Keep stopwords? false\n",
      "2023-05-10 09:50:41,669 INFO  [main] index.IndexCollection (IndexCollection.java:392) - Stopwords: null\n",
      "2023-05-10 09:50:41,669 INFO  [main] index.IndexCollection (IndexCollection.java:393) - Store positions? false\n",
      "2023-05-10 09:50:41,669 INFO  [main] index.IndexCollection (IndexCollection.java:394) - Store docvectors? false\n",
      "2023-05-10 09:50:41,669 INFO  [main] index.IndexCollection (IndexCollection.java:395) - Store document \"contents\" field? true\n",
      "2023-05-10 09:50:41,669 INFO  [main] index.IndexCollection (IndexCollection.java:396) - Store document \"raw\" field? false\n",
      "2023-05-10 09:50:41,669 INFO  [main] index.IndexCollection (IndexCollection.java:397) - Additional fields to index: []\n",
      "2023-05-10 09:50:41,670 INFO  [main] index.IndexCollection (IndexCollection.java:398) - Optimize (merge segments)? false\n",
      "2023-05-10 09:50:41,670 INFO  [main] index.IndexCollection (IndexCollection.java:399) - Whitelist: null\n",
      "2023-05-10 09:50:41,670 INFO  [main] index.IndexCollection (IndexCollection.java:400) - Pretokenized?: false\n",
      "2023-05-10 09:50:41,670 INFO  [main] index.IndexCollection (IndexCollection.java:401) - Index path: ./indeks/\n",
      "2023-05-10 09:50:41,671 INFO  [main] index.IndexCollection (IndexCollection.java:481) - ============ Indexing Collection ============\n",
      "2023-05-10 09:50:41,675 INFO  [main] index.IndexCollection (IndexCollection.java:468) - Using DefaultEnglishAnalyzer\n",
      "2023-05-10 09:50:41,675 INFO  [main] index.IndexCollection (IndexCollection.java:469) - Stemmer: porter\n",
      "2023-05-10 09:50:41,675 INFO  [main] index.IndexCollection (IndexCollection.java:470) - Keep stopwords? false\n",
      "2023-05-10 09:50:41,676 INFO  [main] index.IndexCollection (IndexCollection.java:471) - Stopwords file: null\n",
      "2023-05-10 09:50:41,734 INFO  [main] index.IndexCollection (IndexCollection.java:510) - Thread pool with 1 threads initialized.\n",
      "2023-05-10 09:50:41,734 INFO  [main] index.IndexCollection (IndexCollection.java:512) - Initializing collection in json\n",
      "2023-05-10 09:50:41,734 INFO  [main] index.IndexCollection (IndexCollection.java:521) - 1 file found\n",
      "2023-05-10 09:50:41,735 INFO  [main] index.IndexCollection (IndexCollection.java:522) - Starting to index...\n",
      "2023-05-10 09:50:41,785 DEBUG [pool-2-thread-1] index.IndexCollection$LocalIndexerThread (IndexCollection.java:345) - json/output.json: 10 docs added.\n",
      "2023-05-10 09:50:41,841 INFO  [main] index.IndexCollection (IndexCollection.java:578) - Indexing Complete! 10 documents indexed\n",
      "2023-05-10 09:50:41,841 INFO  [main] index.IndexCollection (IndexCollection.java:579) - ============ Final Counter Values ============\n",
      "2023-05-10 09:50:41,842 INFO  [main] index.IndexCollection (IndexCollection.java:580) - indexed:               10\n",
      "2023-05-10 09:50:41,842 INFO  [main] index.IndexCollection (IndexCollection.java:581) - unindexable:            0\n",
      "2023-05-10 09:50:41,842 INFO  [main] index.IndexCollection (IndexCollection.java:582) - empty:                  0\n",
      "2023-05-10 09:50:41,842 INFO  [main] index.IndexCollection (IndexCollection.java:583) - skipped:                0\n",
      "2023-05-10 09:50:41,842 INFO  [main] index.IndexCollection (IndexCollection.java:584) - errors:                 0\n",
      "2023-05-10 09:50:41,846 INFO  [main] index.IndexCollection (IndexCollection.java:587) - Total 10 documents indexed in 00:00:00\n"
     ]
    }
   ],
   "source": [
    "index_path = './indeks/'\n",
    "\n",
    "!python -m pyserini.index.lucene \\\n",
    "    --collection JsonCollection \\\n",
    "    --input json/ \\\n",
    "    --index ./indeks/ \\\n",
    "    --generator DefaultLuceneDocumentGenerator \\\n",
    "    --threads 1 \\\n",
    "    --storeContents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'q1': {'doc1': {'rank': 1, 'score': 1.9193999767303467}, 'doc2': {'rank': 2, 'score': 0.8185999989509583}}, 'q2': {'doc6': {'rank': 1, 'score': 1.4889999628067017}, 'doc8': {'rank': 2, 'score': 1.4889990091323853}}}\n",
      "Evaluation results for query 'What is the capital of France?':\n",
      "{\n",
      "  \"map\": 0.3333333333333333,\n",
      "  \"recip_rank\": 1.0,\n",
      "  \"ndcg\": 0.46927872602275644\n",
      "}\n",
      "\n",
      "Evaluation results for query 'Who is the author of The Catcher in the Rye?':\n",
      "{\n",
      "  \"map\": 0.25,\n",
      "  \"recip_rank\": 0.5,\n",
      "  \"ndcg\": 0.38685280723454163\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import json\n",
    "from pyserini.search import LuceneSearcher\n",
    "import pytrec_eval\n",
    "index_path = './indeks/'\n",
    "# Load the index using a LuceneSearcher object\n",
    "\n",
    "searcher = LuceneSearcher(index_path)\n",
    "\n",
    "#Set the number of results to retrieve per query\n",
    "hits_per_query = 10\n",
    "searcher.set_bm25(0.9, 0.4)\n",
    "\n",
    "# Define the queries, relevance judgments, and information need descriptions\n",
    "queries = {\n",
    "    'q1': 'What is the capital of France?',\n",
    "    'q2': 'Who is the author of The Catcher in the Rye?',\n",
    "    # ...\n",
    "}\n",
    "\n",
    "qrels = {\n",
    "    'q1': {\n",
    "        'doc1': 1,\n",
    "        'doc2': 0,\n",
    "        'doc3': 1,\n",
    "        'doc4': 0,\n",
    "        'doc5': 1,\n",
    "    },\n",
    "    'q2': {\n",
    "        'doc6': 0,\n",
    "        'doc7': 1,\n",
    "        'doc8': 1,\n",
    "        'doc9': 0,\n",
    "        'doc10': 0,\n",
    "    },\n",
    "    # ...\n",
    "}\n",
    "\n",
    "information_need_descriptions = {\n",
    "    'q1': 'Find information about the capital city of France.',\n",
    "    'q2': 'Find information about the author of The Catcher in the Rye.',\n",
    "    # ...\n",
    "}\n",
    "\n",
    "# Define the evaluation measures to compute\n",
    "measures = {'recip_rank', 'map', 'ndcg'}\n",
    "\n",
    "# Compute the query results and convert them to the format required by Pytrec_eval\n",
    "results = {}\n",
    "for query_id, query_text in queries.items():\n",
    "    hits = searcher.search(query_text, k=hits_per_query)\n",
    "    query_results = {hit.docid: {'rank': i+1, 'score': hit.score} for i, hit in enumerate(hits)}\n",
    "    results[query_id] = query_results\n",
    "print(results)\n",
    "pytrec_eval_qrels = (qrels)\n",
    "\n",
    "# Convert the results dictionary into the format required by Pytrec_eval\n",
    "pytrec_eval_results = {}\n",
    "for query_id, docs in results.items():\n",
    "    for rank, (doc_id, doc_info) in enumerate(docs.items()):\n",
    "        score = doc_info['score']\n",
    "        pytrec_eval_results.setdefault(query_id, {})[doc_id] = score\n",
    "\n",
    "\n",
    "# Create a Pytrec_eval evaluator object and compute the evaluation scores\n",
    "evaluator = pytrec_eval.RelevanceEvaluator(pytrec_eval_qrels, measures)\n",
    "evaluation_scores = evaluator.evaluate(pytrec_eval_results)\n",
    "\n",
    "# Print the evaluation scores for each query\n",
    "for query_id, query_text in queries.items():\n",
    "    print(f\"Evaluation results for query '{query_text}':\")\n",
    "    print(json.dumps(evaluation_scores[query_id], indent=2))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'recip_rank'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Create a Pytrec_eval evaluator object and compute the evaluation scores\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[39m# Get the MRR score from the Pytrec_eval results\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m mrr \u001b[39m=\u001b[39m pytrec_eval_results[\u001b[39m'\u001b[39;49m\u001b[39mrecip_rank\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39m'\u001b[39m\u001b[39mall\u001b[39m\u001b[39m'\u001b[39m][\u001b[39m'\u001b[39m\u001b[39mmean_reciprocal_rank\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m      5\u001b[0m pytrec_eval_results\n",
      "\u001b[0;31mKeyError\u001b[0m: 'recip_rank'"
     ]
    }
   ],
   "source": [
    "# Create a Pytrec_eval evaluator object and compute the evaluation scores\n",
    "\n",
    "# Get the MRR score from the Pytrec_eval results\n",
    "mrr = pytrec_eval_results['recip_rank']['all']['mean_reciprocal_rank']\n",
    "pytrec_eval_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyserini",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
